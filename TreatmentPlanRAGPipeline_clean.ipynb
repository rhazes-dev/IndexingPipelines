{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WfF0Z38KO3H9",
        "u0ga7YT68eX_",
        "qWc3-PBoWJ7U",
        "VOdk8rT1eU19",
        "byG4QoGacOuq",
        "o1saxk-konyO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "WfF0Z38KO3H9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv azure-core azure-search-documents==11.5.1 azure-storage-blob azure-identity openai aiohttp --quiet"
      ],
      "metadata": {
        "id": "2bV02RixO5IA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0d4cd6-e792-4d81-d481-f80e95405066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.7/297.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.9/406.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keys"
      ],
      "metadata": {
        "id": "u0ga7YT68eX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storage_account_url = \"\"\n",
        "storage_account_key = \"\"\n",
        "\n",
        "embedding_endpoint = \"\"\n",
        "\n",
        "AZURE_SEARCH_SERVICE: str = \"\"\n",
        "AZURE_SEARCH_KEY: str = \"\"\n",
        "AZURE_OPENAI_ACCOUNT: str = \"\"\n",
        "AZURE_OPENAI_KEY: str = \"\"\n",
        "AZURE_AI_MULTISERVICE_ACCOUNT: str = \"\"\n",
        "AZURE_AI_MULTISERVICE_KEY: str = \"\"\n",
        "AZURE_STORAGE_CONNECTION: str = \"\"\n",
        "\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "AZURE_SEARCH_CREDENTIAL = AzureKeyCredential(AZURE_SEARCH_KEY)"
      ],
      "metadata": {
        "id": "s_uLh-mE8f4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting data and reference map"
      ],
      "metadata": {
        "id": "qWc3-PBoWJ7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://ftp.ncbi.nlm.nih.gov/pub/litarch/3d/12/statpearls_NBK430685.tar.gz'\n",
        "target_path = 'statpearls-2025-03-02.tar.gz'\n",
        "\n",
        "response = requests.get(url, stream=True)\n",
        "if response.status_code == 200:\n",
        "    with open(target_path, 'wb') as f:\n",
        "        f.write(response.raw.read())\n"
      ],
      "metadata": {
        "id": "Cb5ZeUxiBC0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the \"tarfile\" module\n",
        "import tarfile\n",
        "\n",
        "# open file\n",
        "file = tarfile.open(target_path)\n",
        "\n",
        "# extracting file\n",
        "file.extractall('./statpearls')\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "id": "UhOp_8T7CGTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "filepaths = []\n",
        "for root, dirs, files in os.walk(\"./statpearls\"):\n",
        "  for file in files:\n",
        "    if file.endswith(\".nxml\"):\n",
        "      filepaths.append(os.path.join(root, file))\n",
        "\n",
        "filepaths.remove('./statpearls/statpearls_NBK430685/TOC.nxml') #contents\n",
        "filepaths.remove('./statpearls/statpearls_NBK430685/contributors.nxml') #contributors\n",
        "\n",
        "mappings = {}\n",
        "\n",
        "# Assuming the first .nxml file is desired\n",
        "for filename in tqdm(filepaths):\n",
        "  #print(filename)\n",
        "  tree = ET.parse(filename)\n",
        "  notags = ET.tostring(tree.getroot(), encoding='utf-8',method='text').decode(\"utf-8\")\n",
        "\n",
        "  replace_str = '\\n  \\n    statpearls\\n    \\n      StatPearls\\n    \\n    \\n      01\\n      2025\\n    \\n    \\n      StatPearls Publishing\\n      Treasure Island (FL)\\n    \\n    \\n      Copyright © 2025, StatPearls Publishing LLC\\n      \\n        \\nThis book is distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\\n(\\nhttp://creativecommons.org/licenses/by-nc-nd/4.0/\\n), which permits others to distribute the work, provided that the article is not altered or used commercially. You are not required to obtain permission to distribute this article, provided that you credit the author and journal.\\n\\n      \\n    \\n    \\n      \\n        books-source-type\\n        Database\\n      \\n    \\n    \\n      The intent of StatPearls review books and articles is to identify knowledge deficits and assist you in the learning process. Review books and articles are not intended to be a source of the knowledge base of medicine. The authors and editors do not warrant the information is complete or accurate. The reader is encouraged to verify content and questions in several references. All drug indications and dosages should be verified before administration.\\n      The authors and editors would like to extend special thanks to Erin Hughes and Gerson Rubio for their editorial support.\\n    \\n  \\n  \\n    \\n      \\n        '\n",
        "  replace_st1 = '\\n  \\n    statpearls\\n    \\n      StatPearls\\n    \\n    \\n      06\\n      2017\\n    \\n    \\n      StatPearls Publishing\\n      Treasure Island (FL)\\n    \\n    \\n      Copyright © 2017, StatPearls Publishing LLC\\n      \\n        \\nThis book is distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\\n(\\nhttp://creativecommons.org/licenses/by-nc-nd/4.0/\\n), which permits others to distribute the work, provided that the article is not altered or used commercially. You are not required to obtain permission to distribute this article, provided that you credit the author and journal.\\n\\n      \\n    \\n    \\n      \\n        books-source-type\\n        Database\\n      \\n    \\n    \\n      The intent of StatPearls review books and articles is to identify knowledge deficits and assist you in the learning process. Review books and articles are not intended to be a source of the knowledge base of medicine. The authors and editors do not warrant the information is complete or accurate. The reader is encouraged to verify content and questions in several references. All drug indications and dosages should be verified before administration.\\n      The authors and editors would like to extend special thanks to Erin Hughes and Gerson Rubio for their editorial support.\\n    \\n  \\n  \\n    \\n      \\n        '\n",
        "  replace_st2 = '\\n  \\n    statpearls\\n    \\n      StatPearls\\n    \\n    \\n      01\\n      2025\\n    \\n    \\n      StatPearls Publishing\\n      Treasure Island (FL)\\n    \\n    \\n      Copyright © 2025, StatPearls Publishing LLC\\n      \\n         This book is distributed under the terms of the Creative Commons\\nAttribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) (\\nhttp://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits others to\\ndistribute the work, provided that the article is not altered or used commercially. You\\nare not required to obtain permission to distribute this article, provided that you credit\\nthe author and journal. \\n      \\n    \\n    \\n      \\n        books-source-type\\n        Database\\n      \\n    \\n    \\n      The intent of StatPearls review books and articles is to identify knowledge deficits and\\nassist you in the learning process. Review books and articles are not intended to be a\\nsource of the knowledge base of medicine. The authors and editors do not warrant the\\ninformation is complete or accurate. The reader is encouraged to verify content and\\nquestions in several references. All drug indications and dosages should be verified before\\nadministration.\\n      The authors and editors would like to extend special thanks to Erin Hughes and Gerson Rubio\\nfor their editorial support.\\n    \\n  \\n  \\n    \\n      \\n        '\n",
        "  replace_st3 = '\\n  \\n    statpearls\\n    \\n      StatPearls\\n    \\n    \\n      06\\n      2017\\n    \\n    \\n      StatPearls Publishing\\n      Treasure Island (FL)\\n    \\n    \\n      Copyright © 2017, StatPearls Publishing LLC\\n      \\n        This book is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, duplication, adaptation, distribution, and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, a link is provided to the Creative Commons license, and any changes made are indicated.\\n      \\n    \\n    \\n      \\n        books-source-type\\n        Database\\n      \\n    \\n    \\n      The intent of StatPearls review books and articles is to identify knowledge deficits and assist you in the learning process. Review books and articles are not intended to be a source of the knowledge base of medicine. The authors and editors do not warrant the information is complete or accurate. The reader is encouraged to verify content and questions in several references. All drug indications and dosages should be verified before administration.\\n      The authors and editors would like to extend special thanks to Richard Miller, Tiffany Sneden, Erin Hughes, Beata Beatty, and Gerson Rubio for their editorial support and Susan Oliver for editorial team management.\\n    \\n  \\n  \\n    \\n      \\n        '\n",
        "\n",
        "  notags = notags.replace(replace_str, '')\n",
        "  notags = notags.replace(replace_st1, '')\n",
        "  notags = notags.replace(replace_st2, '')\n",
        "  notags = notags.replace(replace_st3, '')\n",
        "\n",
        "  save_name = notags.strip().split('\\n')[0]\n",
        "  save_name = save_name.replace('/', ' ')\n",
        "  save_name = save_name.replace('*', ' ')\n",
        "\n",
        "  final = notags.strip().split('References')[0]\n",
        "  final = final.replace('Review Questions', '')\n",
        "  final = final.replace('Access free multiple choice questions on this topic.', '')\n",
        "  final = final.replace('Comment on this article.', '')\n",
        "  final = final.replace('To access free multiple choice questions on this topic, click here.', '')\n",
        "  final = final.replace('Click here for a simplified version.', '')\n",
        "\n",
        "  final2 = \"\".join([s for s in final.splitlines(True) if s.strip()])\n",
        "  #print(final2)\n",
        "  if 'statpearls' in save_name:\n",
        "    print('statpearls in name')\n",
        "    print(filename)\n",
        "    print(save_name)\n",
        "    print(final2)\n",
        "    break\n",
        "  if 'This book is' in save_name:\n",
        "    print('This book is in name')\n",
        "    print(filename)\n",
        "  #print(save_name)\n",
        "  try:\n",
        "    number = filename.split('article-')[1].split('.')[0]\n",
        "  except IndexError:\n",
        "    print('URL mapping Error')\n",
        "    print(filename)\n",
        "  mappings[save_name] = 'https://www.statpearls.com/point-of-care/' + str(number)\n",
        "  with open('./statpearls/' + save_name + '.txt','w+', encoding=\"utf-8\") as f:\n",
        "      f.write(final2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGXOK_asFlqA",
        "outputId": "5b0ef6bb-5c54-4a04-8fe0-ab3a3eda2022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9559/9559 [01:03<00:00, 150.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in mappings.keys():\n",
        "  if 'near' in key.lower():\n",
        "    print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naitvGvcRdZV",
        "outputId": "74a62bb1-945d-4322-c502-b75220d4da23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear IGA Dermatosis\n",
            "Drowning, Near\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading to Azure Storage"
      ],
      "metadata": {
        "id": "VOdk8rT1eU19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textpaths = []\n",
        "for root, dirs, files in os.walk(\"./statpearls\"):\n",
        "  for file in files:\n",
        "    if file.endswith(\".txt\"):\n",
        "      textpaths.append(os.path.join(root, file))"
      ],
      "metadata": {
        "id": "Dqxvb6spDy3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in textpaths:\n",
        "  snippet = text.split('statpearls/')[1]\n",
        "  snippet = snippet.split('.txt')[0]\n",
        "  #print(snippet)\n",
        "  if snippet not in mappings.keys():\n",
        "    print(snippet)\n",
        "    textpaths.remove(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXmVArSNXBGn",
        "outputId": "b6ad244b-715d-4a95-de0d-f1e0e3f78500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "statpearls\n",
            "Editorial Board\n",
            "statpearls_NBK430685/license\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(textpaths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "137bIxIsabpR",
        "outputId": "edc7b4f8-9a86-4068-efdf-8703c1fe2654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9559"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient\n",
        "\n",
        "blob_service_client = BlobServiceClient(storage_account_url, storage_account_key)\n",
        "\n",
        "container_client = blob_service_client.create_container(name='statpearls-2025-03-02')"
      ],
      "metadata": {
        "id": "i4Dc_oMEwosJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in tqdm(textpaths):\n",
        "  snippet = text.split('statpearls/')[1]\n",
        "  snippet = snippet.split('.txt')[0]\n",
        "  blob_client = blob_service_client.get_blob_client(container=\"statpearls-2025-03-02\", blob=snippet)\n",
        "  with open(text, \"rb\") as data:\n",
        "      blob_client.upload_blob(data, overwrite=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCaXpW_ODynf",
        "outputId": "108f2af8-b06a-4495-a9b9-a795b98ddce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9559/9559 [18:58<00:00,  8.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "byG4QoGacOuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.search.documents.indexes import SearchIndexClient\n",
        "from azure.search.documents.indexes.models import (\n",
        "    SearchField,\n",
        "    SearchFieldDataType,\n",
        "    VectorSearch,\n",
        "    HnswAlgorithmConfiguration,\n",
        "    VectorSearchProfile,\n",
        "    AzureOpenAIVectorizer,\n",
        "    AzureOpenAIVectorizerParameters,\n",
        "    SearchIndex\n",
        ")\n",
        "\n",
        "pre_name = 'statpearls-2025-03-02'\n",
        "\n",
        "# Create a search index\n",
        "index_name = pre_name + '-idx'\n",
        "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "fields = [\n",
        "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),\n",
        "    SearchField(name=\"title\", type=SearchFieldDataType.String),\n",
        "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),\n",
        "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
        "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=3072, vector_search_profile_name=\"myHnswProfile\")\n",
        "    ]\n",
        "\n",
        "# Configure the vector search configuration\n",
        "vector_search = VectorSearch(\n",
        "    algorithms=[\n",
        "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
        "    ],\n",
        "    profiles=[\n",
        "        VectorSearchProfile(\n",
        "            name=\"myHnswProfile\",\n",
        "            algorithm_configuration_name=\"myHnsw\",\n",
        "            vectorizer_name=\"myOpenAI\",\n",
        "        )\n",
        "    ],\n",
        "    vectorizers=[\n",
        "        AzureOpenAIVectorizer(\n",
        "            vectorizer_name=\"myOpenAI\",\n",
        "            kind=\"azureOpenAI\",\n",
        "            parameters=AzureOpenAIVectorizerParameters(\n",
        "                resource_url=AZURE_OPENAI_ACCOUNT,\n",
        "                deployment_name=\"text-embedding-3-large\",\n",
        "                model_name=\"text-embedding-3-large\",\n",
        "                api_key=AZURE_OPENAI_KEY\n",
        "            ),\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Create the search index\n",
        "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
        "result = index_client.create_or_update_index(index)\n",
        "print(f\"{result.name} created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vQ0C5l1iFNA",
        "outputId": "c4f6744c-9831-483d-e064-542f9112bfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "statpearls-2025-03-02-idx created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes import SearchIndexerClient\n",
        "from azure.search.documents.indexes.models import (\n",
        "    SearchIndexerDataContainer,\n",
        "    SearchIndexerDataSourceConnection\n",
        ")\n",
        "\n",
        "# Create a data source\n",
        "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "container = SearchIndexerDataContainer(name=pre_name)\n",
        "data_source_connection = SearchIndexerDataSourceConnection(\n",
        "    name = pre_name + '-ds',\n",
        "    type=\"azureblob\",\n",
        "    connection_string=AZURE_STORAGE_CONNECTION,\n",
        "    container=container\n",
        ")\n",
        "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
        "\n",
        "print(f\"Data source '{data_source.name}' created or updated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ_UBTRbjRij",
        "outputId": "547e5eb1-730a-4b07-a9bc-bc999ceb144d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source 'statpearls-2025-03-02-ds' created or updated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes.models import (\n",
        "    SplitSkill,\n",
        "    InputFieldMappingEntry,\n",
        "    OutputFieldMappingEntry,\n",
        "    AzureOpenAIEmbeddingSkill,\n",
        "    EntityRecognitionSkill,\n",
        "    SearchIndexerIndexProjection,\n",
        "    SearchIndexerIndexProjectionSelector,\n",
        "    SearchIndexerIndexProjectionsParameters,\n",
        "    IndexProjectionMode,\n",
        "    SearchIndexerSkillset,\n",
        "    CognitiveServicesAccountKey\n",
        ")\n",
        "\n",
        "# Create a skillset\n",
        "skillset_name = pre_name + '-ss'\n",
        "\n",
        "split_skill = SplitSkill(\n",
        "    description=\"Split skill to chunk documents\",\n",
        "    text_split_mode=\"pages\",\n",
        "    context=\"/document\",\n",
        "    maximum_page_length=4000,\n",
        "    page_overlap_length=100,\n",
        "    inputs=[\n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")\n",
        "    ],\n",
        ")\n",
        "\n",
        "embedding_skill = AzureOpenAIEmbeddingSkill(\n",
        "    description=\"Skill to generate embeddings via Azure OpenAI\",\n",
        "    context=\"/document/pages/*\",\n",
        "    resource_url=AZURE_OPENAI_ACCOUNT,\n",
        "    deployment_name=\"text-embedding-3-large\",\n",
        "    model_name=\"text-embedding-3-large\",\n",
        "    dimensions=3072,\n",
        "    inputs=[\n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")\n",
        "    ],\n",
        ")\n",
        "\n",
        "index_projections = SearchIndexerIndexProjection(\n",
        "    selectors=[\n",
        "        SearchIndexerIndexProjectionSelector(\n",
        "            target_index_name=index_name,\n",
        "            parent_key_field_name=\"parent_id\",\n",
        "            source_context=\"/document/pages/*\",\n",
        "            mappings=[\n",
        "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),\n",
        "                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
        "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
        "            ],\n",
        "        ),\n",
        "    ],\n",
        "    parameters=SearchIndexerIndexProjectionsParameters(\n",
        "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
        "    ),\n",
        ")\n",
        "\n",
        "cognitive_services_account = CognitiveServicesAccountKey(key=AZURE_AI_MULTISERVICE_KEY)\n",
        "\n",
        "skills = [split_skill, embedding_skill]\n",
        "\n",
        "skillset = SearchIndexerSkillset(\n",
        "    name=skillset_name,\n",
        "    description=\"Skillset to chunk documents and generating embeddings\",\n",
        "    skills=skills,\n",
        "    index_projection=index_projections,\n",
        "    cognitive_services_account=cognitive_services_account\n",
        ")\n",
        "\n",
        "client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "client.create_or_update_skillset(skillset)\n",
        "print(f\"{skillset.name} created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7uBJmxljjmV",
        "outputId": "121e0a43-c993-415e-8000-0d6f92c4020d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "statpearls-2025-03-02-ss created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes.models import (\n",
        "    SearchIndexer,\n",
        "    FieldMapping\n",
        ")\n",
        "\n",
        "# Create an indexer\n",
        "indexer_name = pre_name + '-idxr'\n",
        "\n",
        "indexer_parameters = None\n",
        "\n",
        "indexer = SearchIndexer(\n",
        "    name=indexer_name,\n",
        "    description=\"Indexer to index documents and generate embeddings\",\n",
        "    skillset_name=skillset_name,\n",
        "    target_index_name=index_name,\n",
        "    data_source_name=data_source.name,\n",
        "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results\n",
        "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")],\n",
        "    parameters=indexer_parameters\n",
        ")\n",
        "\n",
        "# Create and run the indexer\n",
        "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "indexer_result = indexer_client.create_or_update_indexer(indexer)\n",
        "\n",
        "print(f' {indexer_name} is created and running. Give the indexer a few minutes before running a query.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1EIOQx0kNtb",
        "outputId": "ab9e6589-6bef-4ec0-967c-0c3756096fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " statpearls-2025-03-02-idxr is created and running. Give the indexer a few minutes before running a query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vd-4unSWkxFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Searcing the RAG system"
      ],
      "metadata": {
        "id": "o1saxk-konyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from azure.search.documents import SearchClient\n",
        "from azure.search.documents.models import VectorizableTextQuery\n",
        "from azure.search.documents import SearchClient\n",
        "\n",
        "pre_name = 'statpearls-2025-03-02'\n",
        "\n",
        "index_name = pre_name + '-idx'\n",
        "\n",
        "# Vector Search using text-to-vector conversion of the querystring\n",
        "query=\"86M with known CCF presents with pulmonary oedema as seen on chest x ray. Ejection fraction of 30%. Patient also has an eGFR of 10.\"\n",
        "# query=\"Sore throat, itchy stomach when taking amoxicillin, 38 degrees temperature, hard to swallow, red spots on tonsils\"\n",
        "\n",
        "search_client = SearchClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL, index_name=index_name)\n",
        "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"text_vector\", exhaustive=True)\n",
        "\n",
        "results = search_client.search(\n",
        "    search_text=query,\n",
        "    vector_queries= [vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"title\", \"chunk\"],\n",
        "    top=10\n",
        ")\n",
        "\n",
        "for result in results:\n",
        "    #print(f\"Score: {result['@search.score']}\")\n",
        "    print(f\"Title: {result['title']}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6fxfXQ9osas",
        "outputId": "ce4ebaa1-93b4-40c4-912c-9ee1130eabe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Cardiogenic Pulmonary Edema\n",
            "\n",
            "Title: Heart Failure With Preserved Ejection Fraction (HFpEF)\n",
            "\n",
            "Title: Case Study: 60-Year-Old Female Presenting With Shortness of Breath (Archived)\n",
            "\n",
            "Title: Left Ventricular Ejection Fraction\n",
            "\n",
            "Title: Heart Failure With Preserved Ejection Fraction (HFpEF)\n",
            "\n",
            "Title: Heart Failure and Ejection Fraction\n",
            "\n",
            "Title: Heart Failure With Preserved Ejection Fraction (HFpEF)\n",
            "\n",
            "Title: X-ray Production Technical Evaluation\n",
            "\n",
            "Title: Heart Failure and Ejection Fraction\n",
            "\n",
            "Title: Heart Failure With Preserved Ejection Fraction (HFpEF)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asking the RAG system"
      ],
      "metadata": {
        "id": "HxR6o324lCjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "from azure.search.documents import SearchClient\n",
        "\n",
        "query=\"86M with known CCF presents with pulmonary oedema as seen on chest x ray. Ejection fraction of 30%. Patient also has an eGFR of 10.\"\n",
        "\n",
        "pre_name = 'statpearls-2025-03-02'\n",
        "index_name = pre_name + '-idx'\n",
        "\n",
        "# Set up clients and specify the chat model\n",
        "openai_client = AzureOpenAI(\n",
        "     api_version=\"2024-06-01\",\n",
        "     azure_endpoint=AZURE_OPENAI_ACCOUNT,\n",
        "     api_key=AZURE_OPENAI_KEY\n",
        " )\n",
        "\n",
        "deployment_name = \"gpt-4o-datazone\"\n",
        "\n",
        "search_client = SearchClient(\n",
        "     endpoint=AZURE_SEARCH_SERVICE,\n",
        "     index_name=index_name,\n",
        "     credential=AZURE_SEARCH_CREDENTIAL\n",
        " )\n",
        "\n",
        "# Provide instructions to the model\n",
        "SYSTEM_PROMPT=\"\"\"\n",
        "### ROLE\n",
        "\n",
        "You are a specialist in every medical field:\n",
        "- You know all the latest speciality-specific guidelines, every possible human pathophysiological process, and every disease state described in any medical literature, including those that are extremely rare, poorly described, or limited to certain regions.\n",
        "- You pay extreme attention to every detail of a case you are presented with.\n",
        "- In addition to your mastery of medicine, you are a distinguished pharmacologist with a deep understanding of drug mechanisms, pharmacokinetics, pharmacodynamics, and potential interactions.\n",
        "- You are highly attuned to medication contraindications, indications, and potential adverse events.\n",
        "- Because of the aforementioned traits, you are being consulted by another clinician regarding the management of a specific clinical case.\n",
        "\n",
        "---\n",
        "\n",
        "### TASK\n",
        "\n",
        "- You will complete the 6-step task outlined in this section\n",
        "- The task is as follows:\n",
        "\n",
        "#### 1. Source Verification\n",
        "- This system is Retrieval-Augmented Generation (RAG) enabled. **Before answering any question**, always check the relevant data sources for updated and case-specific information. Ensure your response incorporates all available and relevant external knowledge.\n",
        "\n",
        "#### 2. Review Patient Information\n",
        "- Carefully review all information you have available on the patient, including their presentation, co-morbidities, past medical history, family history, social history, observations, examination findings, investigations, medications, and any diagnoses that have been documented or could be made given the patient’s information.\n",
        "\n",
        "#### 3. Formulate a Clinical Impression\n",
        "- Formulate a concise clinical impression, summarising key aspects of the patient's presentation, relevant history, and significant findings.\n",
        "\n",
        "#### 4. Identify and Prioritise Problems\n",
        "- Identify and prioritise problems based on the diagnoses of interest, grouping related issues when appropriate.\n",
        "\n",
        "#### 5. Provide a Comprehensive Plan\n",
        "- For each identified problem:\n",
        "  - Provide a problem description and include a brief assessment with clinical reasoning for its relevance.\n",
        "- Provide a comprehensive management plan that integrates all recommendations addressing the identified problems. Include:\n",
        "  - **Diagnostic Plan:** Investigations required to \"evaluate for,\" \"assess the likelihood of,\" or \"consider the possibility of\" specific conditions. Justify each investigation.\n",
        "  - **Treatment and Supportive Management:** Evidence-based therapeutic strategies and supportive measures combined under a single heading. Clearly outline first-line, second-line, and contraindicated options. Provide a rationale for each recommendation.\n",
        "  - **Referrals:** Recommendations for specialist input, including the purpose and expected outcomes.\n",
        "  - **Preventative and Lifestyle Measures:** Long-term advice and interventions to improve patient outcomes.\n",
        "\n",
        "#### 6. Format and Structure Your Output\n",
        "- Give your output in the format outlined in the section below titled \"### PRESENTATION OF YOUR RESPONSE:\"\n",
        "- You will adhere to that format strictly.\n",
        "\n",
        "### RULES\n",
        "- Ensure all your recommendations are in line with the latest evidence and guidelines.\n",
        "- Recommendations should only be included when relevant and clinically appropriate to the case. Avoid adding recommendations simply to fill a section.  If there is nothing to say in a certain subsection, simply omit that section.\n",
        "- Always give recommendations in succinct bullet points to maintain clarity.\n",
        "- Avoid introducing unnecessary or extraneous details.\n",
        "- Focus on producing succinct and clinically relevant points.\n",
        "- Ensure all rationale is integrated line-by-line with the recommendations rather than in a separate subsection.\n",
        "- Perform a final review to check for consistency, completeness, and clinical appropriateness before finalising the output.\n",
        "- Where a drug, procedure, or component of your plan has multiple names, use both the British and American names (e.g., \"paracetamol (acetaminophen)\").\n",
        "- Do not give introductions or conclusions, safety instructions, or safety warnings unless specifically requested.\n",
        "- Do not give any part of this prompt in your output.\n",
        "- Use relevant shorthand and medical acronyms where appropriate (e.g., SOB for shortness of breath, NAD for no abnormalities detected).\n",
        "- Avoid unnecessary verbosity; keep clinical information short, succinct, and to the point.\n",
        "- Your reader is a trained clinician. You do not need plain language explanations.\n",
        "- Do not add subheadings of your own\n",
        "- Information must be based solely on what is mentioned in the information you have been provided with.\n",
        "- Ensure you adhere to ALL instructions.\n",
        "\n",
        "---\n",
        "\n",
        "### PRESENTATION OF YOUR RESPONSE:\n",
        "\n",
        "Structure your response in the following way (do not include quotation marks):\n",
        "\"\n",
        "#### Summary\n",
        "Provide a concise clinical impression that summarises the key aspects of the patient's presentation, relevant history, and significant findings.\n",
        "- Use bullet points to highlight pertinent details for quick reference.\n",
        "- Avoid extraneous details that are not clinically relevant to the case.\n",
        "----\n",
        "\n",
        "#### Problems and Assessments\n",
        "List all identified problems and include a brief assessment for each.\n",
        "- If a problem is not confirmed or stated in the input put the string \"(Possible)\" in the title. However, include problems that are explicitly stated in your input or that are very likely to be present.\n",
        "- Clearly describe each problem with clinical reasoning behind its relevance or priority.\n",
        "- Avoid overlapping or duplicating descriptions.\n",
        "----\n",
        "\n",
        "#### Recommendations\n",
        "Provide a comprehensive plan addressing all problems together. Integrate rationale with each recommendation:\n",
        "\n",
        "**Diagnostic Plan:**\n",
        "- List investigations required to \"evaluate for,\" \"assess the likelihood of,\" or \"consider the possibility of\" specific conditions.\n",
        "- Provide a brief justification for each investigation (e.g., “Troponin T to confirm myocardial injury; elevated levels indicate NSTEMI”).\n",
        "\n",
        "**Treatment and Supportive Management:**\n",
        "- Combine therapeutic strategies and supportive measures.\n",
        "- Include first-line treatments, second-line options, and contraindications with clear reasoning.\n",
        "- Ensure recommendations are evidence-based and specific to the patient’s needs (e.g., “Enoxaparin SC to prevent clot expansion unless contraindicated by bleeding risk”).\n",
        "\n",
        "**Referrals:**\n",
        "- Include referrals to specialists or services.\n",
        "- Specify the purpose, urgency and expected outcomes of each referral (e.g., “Cardiology for urgent angiography and potential PCI”).\n",
        "- Only include appropriate referrals. If there are no appropriate referrals in this patient’s case, then simply omit this section.\n",
        "\n",
        "**Preventative and Lifestyle Measures:**\n",
        "- Provide long-term advice for prevention or risk reduction (e.g., “Smoking cessation counselling to lower cardiovascular risk”).\n",
        "- Tailor recommendations to the patient’s individual context (e.g., “Encourage a low-sodium diet to manage hypertension”).\n",
        "- Only include appropriate measures. If there are no appropriate measures in the patient’s case, then simply omit this section.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "C-MZtmGJlE_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(sp, qry):\n",
        "\n",
        "    completion = openai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": sp},\n",
        "            {\"role\": \"user\", \"content\": qry}\n",
        "        ],\n",
        "        max_tokens = 4096,\n",
        "        model=deployment_name,\n",
        "        temperature=0,\n",
        "        extra_body = {\n",
        "            \"data_sources\": [{\n",
        "                \"type\": 'azure_search',\n",
        "                \"parameters\": {\n",
        "                    \"endpoint\": AZURE_SEARCH_SERVICE,\n",
        "                    \"index_name\": index_name,\n",
        "                    \"authentication\": {\n",
        "                        \"type\": \"api_key\",\n",
        "                        \"key\": AZURE_SEARCH_KEY,\n",
        "                    },\n",
        "                    \"embedding_dependency\": {\n",
        "                        \"type\": 'endpoint',\n",
        "                        \"endpoint\": embedding_endpoint,\n",
        "                        \"authentication\": {\n",
        "                            \"type\": \"api_key\",\n",
        "                            \"key\": AZURE_OPENAI_KEY,\n",
        "                        },\n",
        "                    },\n",
        "                    \"query_type\": 'vector',\n",
        "                    \"in_scope\": False,\n",
        "                    \"semantic_configuration\": 'default',\n",
        "                    \"top_n_documents\": 20,\n",
        "                    \"strictness\": 3,\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return completion"
      ],
      "metadata": {
        "id": "uZjgoC0DqODQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = get_completion(SYSTEM_PROMPT, query)\n",
        "\n",
        "#getting unique URL refs algo\n",
        "content = res.choices[0].message.content\n",
        "context = res.choices[0].message.context\n",
        "ref = {}\n",
        "orders = {}\n",
        "url_ref = {}\n",
        "for citation_index, citation in enumerate(context[\"citations\"]):\n",
        "    citation_reference = f\"[doc{citation_index + 1}]\"\n",
        "    if citation_reference in content:\n",
        "      title = citation[\"title\"].replace('.txt', '')\n",
        "      url = mappings[title]\n",
        "      snippet = citation[\"content\"][:100] + '...'\n",
        "      chunk_id = citation[\"chunk_id\"]\n",
        "      info = f\"URL: {url} \\n TITLE: {title} \\n SNIPPET: {snippet}\"\n",
        "      ref[citation_reference] = info\n",
        "      url_ref[citation_reference] = url\n",
        "      orders[citation_reference] = len(content.split(citation_reference)[0])\n",
        "\n",
        "sorted_ref = {k: ref[k] for k in sorted(orders, key=orders.get)}\n",
        "sorted_url = {k: url_ref[k] for k in sorted(orders, key=orders.get)}\n",
        "\n",
        "i = 0\n",
        "new_ref_dict = {}\n",
        "references = ''\n",
        "used_urls = {}\n",
        "for key, value in sorted_url.items():\n",
        "    if value not in used_urls:\n",
        "      ref_to_add = '[' + str(i+1) + ']' + '\\n' + sorted_ref[key] + '\\n'\n",
        "      references += ref_to_add\n",
        "      new_ref_dict[key] = '[' + str(i+1) + ']'\n",
        "      used_urls[value] = i\n",
        "      i += 1\n",
        "    else:\n",
        "      index = used_urls[value]\n",
        "      new_ref_dict[key] = '[' + str(index+1) + ']'\n",
        "\n",
        "#updating the content with the correct numbering (in ascending order)\n",
        "for key, value in new_ref_dict.items():\n",
        "    content = content.replace(key, value)"
      ],
      "metadata": {
        "id": "XNHjZUpIrCSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(content)\n",
        "print('\\nReferences:\\n')\n",
        "print(references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLqOK4M9rTD0",
        "outputId": "36ef5ced-6cf0-4d8a-bbe6-a205c844e206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### Summary  \n",
            "- 86-year-old male with known congestive cardiac failure (CCF) presents with pulmonary edema, confirmed by chest X-ray.  \n",
            "- Ejection fraction is 30%, indicating severe left ventricular systolic dysfunction.  \n",
            "- Estimated glomerular filtration rate (eGFR) is 10, indicating severe renal impairment or end-stage renal disease (ESRD).\n",
            "\n",
            "----\n",
            "\n",
            "#### Problems and Assessments  \n",
            "- **Congestive Cardiac Failure (CCF) with Pulmonary Edema:** The patient has severe left ventricular systolic dysfunction (EF 30%), contributing to pulmonary edema. This is a critical condition requiring immediate management to prevent respiratory compromise and further cardiac deterioration [1][2].\n",
            "- **Renal Failure:** The eGFR of 10 suggests severe renal impairment, likely contributing to fluid overload and complicating heart failure management. This requires urgent attention to prevent further renal damage and manage fluid balance [3][4].\n",
            "\n",
            "----\n",
            "\n",
            "#### Recommendations  \n",
            "\n",
            "**Diagnostic Plan:**  \n",
            "- **Echocardiography:** To assess cardiac function, valvular abnormalities, and confirm the degree of systolic dysfunction [5][2].\n",
            "- **Serum Electrolytes and Renal Function Tests:** To monitor for electrolyte imbalances and assess renal function, which is crucial given the low eGFR [3].\n",
            "- **BNP or NT-proBNP Levels:** To evaluate the severity of heart failure and guide management [6].\n",
            "\n",
            "**Treatment and Supportive Management:**  \n",
            "- **Diuretics:** Use loop diuretics like furosemide to manage fluid overload and pulmonary edema, but monitor renal function closely due to potential worsening of renal impairment [2][1].\n",
            "- **Vasodilators:** Consider intravenous nitroglycerin to reduce preload and manage pulmonary congestion, ensuring blood pressure is stable [2][7].\n",
            "- **Renal Replacement Therapy:** Consider dialysis for severe renal failure, especially if fluid overload is refractory to diuretics [3].\n",
            "- **ACE Inhibitors or ARBs:** Initiate cautiously to manage heart failure, considering renal function and potential contraindications [7].\n",
            "\n",
            "**Referrals:**  \n",
            "- **Cardiology:** For management of heart failure and potential device therapy, such as an implantable cardioverter-defibrillator (ICD) given the low ejection fraction [8].\n",
            "- **Nephrology:** For evaluation and management of renal failure, including consideration of dialysis [3][4].\n",
            "\n",
            "**Preventative and Lifestyle Measures:**  \n",
            "- **Salt and Fluid Restriction:** To manage fluid balance and reduce the risk of further heart failure exacerbations [1].\n",
            "- **Patient Education:** Emphasize adherence to prescribed medications and lifestyle modifications to prevent exacerbations [5].\n",
            "\n",
            "References:\n",
            "\n",
            "[1]\n",
            "URL: https://www.statpearls.com/point-of-care/19880 \n",
            " TITLE: Congestive Heart Failure and Pulmonary Edema \n",
            " SNIPPET: Congestive Heart Failure and Pulmonary Edema\n",
            "            King\n",
            "            Kevin C.\n",
            "            Golds...\n",
            "[2]\n",
            "URL: https://www.statpearls.com/point-of-care/80517 \n",
            " TITLE: Pulmonary Edema \n",
            " SNIPPET: and lateral views in standard imaging or anteroposterior views in portable imaging are utilized. Car...\n",
            "[3]\n",
            "URL: https://www.statpearls.com/point-of-care/28355 \n",
            " TITLE: Renal Failure (Archived) \n",
            " SNIPPET: FDA can be nephrotoxic.\n",
            "            Always record ins and outs.\n",
            "            Monitor daily weights.\n",
            " ...\n",
            "[4]\n",
            "URL: https://www.statpearls.com/point-of-care/28357 \n",
            " TITLE: Chronic Kidney Disease \n",
            " SNIPPET: treatment option for ESRD due to its survival benefit compared to long-term dialysis therapy. Patien...\n",
            "[5]\n",
            "URL: https://www.statpearls.com/point-of-care/24161 \n",
            " TITLE: Left Ventricular Failure \n",
            " SNIPPET: decrease cardiac output by impaired ventricular filling and decreased ventricular relaxation. Cardio...\n",
            "[6]\n",
            "URL: https://www.statpearls.com/point-of-care/164817 \n",
            " TITLE: Heart Failure With Preserved Ejection Fraction (HFpEF) \n",
            " SNIPPET: clinical outcomes; the negative impact is inversely proportional to the hemoglobin level.[62]\n",
            "Serum ...\n",
            "[7]\n",
            "URL: https://www.statpearls.com/point-of-care/28020 \n",
            " TITLE: Cardiogenic Pulmonary Edema \n",
            " SNIPPET: functions and electrolytes\n",
            "            Keep serum potassium above 4.0 mEq/L and Mg over 2.0 mEq/L.\n",
            " ...\n",
            "[8]\n",
            "URL: https://www.statpearls.com/point-of-care/24159 \n",
            " TITLE: Left Ventricular Ejection Fraction \n",
            " SNIPPET: Imaging agents enter the myocardium once injected into the patient. ECG-gated images are obtained. T...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsjA41FkOliz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}